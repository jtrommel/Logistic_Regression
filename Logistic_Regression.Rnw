\documentclass{tufte-book}
\usepackage{graphicx}  % werken met figuren
\usepackage{gensymb} % werken met wetenschappelijke eenheden\usepackage{geometry}
\usepackage{changepage} % http://ctan.org/pkg/changepage
\usepackage[dutch,british]{babel} % instelling van de taal (woordsplitsing, spellingscontrole)
\usepackage[parfill]{parskip} % Paragrafen gescheiden door witte lijn en geen inspringing
\usepackage[font=small,skip=3pt]{caption} % Minder ruimte tussen figuur/table en ondertitel. Ondertitel klein
\usepackage{capt-of}
\usepackage{indentfirst}
\setlength{\parindent}{0.7cm}
\usepackage{enumitem} % Laat enumerate werken met letters
\usepackage{url}
\usepackage{lipsum}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
% Prints a trailing space in a smart way.
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{amsmath}

\DeclareGraphicsExtensions{.pdf,.png,.jpg}

% Alter some LaTeX defaults for better treatment of figures:
% See p.105 of "TeX Unbound" for suggested values.
% See pp. 199-200 of Lamport's "LaTeX" book for details.
%   General parameters, for ALL pages:
    \renewcommand{\topfraction}{0.9}	% max fraction of floats at top
    \renewcommand{\bottomfraction}{0.9}	% max fraction of floats at bottom
%   Parameters for TEXT pages (not float pages):
    \setcounter{topnumber}{2}
    \setcounter{bottomnumber}{2}
    \setcounter{totalnumber}{4}     % 2 may work better
    \renewcommand{\textfraction}{0.1}	% allow minimal text w. figs
%   Parameters for FLOAT pages (not text pages):
    \renewcommand{\floatpagefraction}{0.8}	% require fuller float pages
% N.B.: floatpagefraction MUST be less than topfraction !!
\setcounter{secnumdepth}{3}

\newcommand{\tthdump}[1]{#1}

\newcommand{\openepigraph}[2]{
  \begin{fullwidth}
  \sffamily\large
    \begin{doublespace}
      \noindent\allcaps{#1}\\ % epigraph
      \noindent\allcaps{#2} % author
    \end{doublespace}
  \end{fullwidth}
}


\usepackage{makeidx}
\makeindex

\title{Logistic Regression}
\author{Jan Trommelmans}

\begin{document}
\SweaveOpts{concordance=TRUE,prefix.string=LR}
\setkeys{Gin}{width=1.1\marginparwidth} %% Sweave

<<echo=FALSE>>=
library(tidyverse)
library(gridExtra)
library(scatterplot3d)
@

% Setting the ggplot theme:
<<echo=FALSE>>=
JT.theme <- theme(panel.border = element_rect(fill = NA, colour = "gray10"),
                  panel.background = element_blank(),
                  panel.grid.major = element_line(colour = "gray85"),
                  panel.grid.minor = element_line(colour = "gray85"),
                  panel.grid.major.x = element_line(colour = "gray85"),
                  axis.text = element_text(size = 8 , face = "bold"),
                  axis.title = element_text(size = 9 , face = "bold"),
                  plot.title = element_text(size = 12 , face = "bold"),
                  strip.text = element_text(size = 8 , face = "bold"),
                  strip.background = element_rect(colour = "black"),
                  legend.text = element_text(size = 8),
                  legend.title = element_text(size = 9 , face = "bold"),
                  legend.background = element_rect(fill = "white"),
                  legend.key = element_rect(fill = "white"))
@

% Functions

\frontmatter
\chapter*{Logistic Regression}

\mainmatter
\chapter{Why do we need a logistic regression?}

\section{Y is a discrete variable with two possible values}

Let us start with the situation where the response variable $Y$ can only have two (discrete) levels ''Yes" and ''No", or ''Dead" and ''Alive". Usually we asign the value ''1" to one outcome and ''0" to the other. Strictly speaking these should not be viewed as actual numbers. We assume that there is only one controllable factor $x$. Let us say that for small values of $x$ the response is ''0", for large values of $x$ the response is ''1". This general description can still give rise to very different situations. It all depends on the region in between: we can go from a situation with a very clear distinction, a fuzzy middle or a fuzzy all round (Figure~\ref{fig:distinct}).

<<label=distinction,fig=TRUE,include=FALSE, echo=FALSE>>=
df_clear <- data.frame(x=seq(-10,10,0.5),y=0)
df_clear$y <- ifelse(df_clear$x<0,0,1)
df_clear$y <- ifelse(df_clear$x==0,0.5,df_clear$y)
p1 <- ggplot(data=df_clear) + 
  geom_point(aes(x=x, y=y), color="red") +
    labs(title="Clear distinction", xlab="x", ylab="y") +
  JT.theme
set.seed(2017)
df_fuzzy_middle <- data.frame(x=seq(-10,10,0.5),y=0)
df_fuzzy_middle$y[17:25] <- rbinom(9,1,0.5)
df_fuzzy_middle$y[26:41] <- 1
p2 <- ggplot(data=df_fuzzy_middle) + 
  geom_point(aes(x=x, y=y), color="red") +
    labs(title="Fuzzy middle", xlab="x", ylab="y") +
  JT.theme
df_fuzzy_complete <- data.frame(x=seq(-10,10,0.5),y=0)
df_fuzzy_middle$y <- rbinom(41,1,0.5)
p3 <- ggplot(data=df_fuzzy_middle) + 
  geom_point(aes(x=x, y=y), color="red") +
    labs(title="Fuzzy all round", xlab="x", ylab="y") +
  JT.theme
grid.arrange(p1, p2, p3, ncol=3)
@

\begin{figure}
\includegraphics[width=200pt, height=200pt]{LR-distinction}
\caption{Some situations}
\label{fig:distinct}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}

\subsection{What are the problems when we use simple linear regression?}
When the response variable $Y$ in \emph{qualitative} rather than \emph{quantitative}, linear regression is not the best method to link $Y$ with the controllable factors $x_{i}$\sidenote{Y (in capital) is a probability variable, x (lower case) is known}. 

\newthought{When $Y$ can only have two values} we have a \emph{dichotomous} event: the image of $Y$ is $\{0,1\}$, with $P[Y=1]=\pi$ and $P[Y=0]=1-\pi$. We do not know all values of $Y$, but we have a sample (size=$n$) of $n$ pairs $(x_{i}, y_{i})$. However, the probability $\pi$ could be different for different values of $x_{i}$:

\begin{equation}
P[Y_{i}=1]=\pi_{i} \quad and \quad P[Y_{i}=0]=1-\pi_{i}
\end{equation}

The expected value of $Y_{i}$ is than

\begin{equation}
E(Y_{i})=1\pi_{i} + 0(1-\pi_{i})=\pi_{i}
\label{eq:meanpi}
\end{equation}

When we use a \emph{simple linear regression} we take it that the relation between $Y$ and $x$ can be written as:

\begin{equation}
Y=\beta_{0} + \beta_{1}x
\end{equation}

The pairs $(x_{i}, Y_{i})$ will not neccesarily lie on the theoretical regression line: there will be some error $\epsilon_{i}$

\begin{equation}
Y_{i}=\beta_{0} + \beta_{1}x_{i} + \epsilon_{i}
\end{equation}

\newthought{Problem 1: linear models give values outside the [0,1] range}

When we calculate the expected value of $Y_{i}$ we get:

\begin{equation}
E(Y_{i})=E\left( \beta_{0} + \beta_{1}x_{i} + \epsilon_{i}  \right) = \beta_{0} + \beta_{1}x_{i}
\label{eq:meanlin}
\end{equation}

From \ref{eq:meanpi} and \ref{eq:meanlin} it follows that

\begin{equation}
\pi_{i}=\beta_{0} + \beta_{1}x_{i}
\label{eq:linkpimean}
\end{equation}

This means that all the values of $\beta_{0} + \beta_{1}x_{i}$ should lie between 0 and 1, because $\pi_{i}$ is a probability. This is not always the case when $\beta_{0}$ and $\beta_{1}$ are determined using the least squares method.

\newthought{Problem 2: the error term $\epsilon_{i}$ is not normally distributed}

From \ref{eq:linkpimean} it follows that the error can only have two values:

\begin{equation}
\begin{split}
\epsilon_{i}&=1-\beta_{0} - \beta_{1}x_{i} \quad if \quad Y_{i}=1 \\
\epsilon_{i}&=-\beta_{0} - \beta_{1}x_{i} \quad if \quad Y_{i}=0
\end{split}
\end{equation}

With only two possible values, $\epsilon_{i}$ is dichotomous and \emph{not} normally distributed.

\newthought{Problem 3: the variance of the error $\epsilon_{i}$ is not constant}

The variance of the error is equal to the variance of the response variable, because
\begin{equation}
var(\epsilon_{i})=var(Y_{i}-\pi_{i})=var(Y_{i}) \quad because \quad \pi_{i}=cnst
\end{equation}

The variance of the response variable is:
\begin{equation}
\begin{split}
var(Y_{i}) & \overset{\Delta}{=} E\left( (Y_{i} - E\left( Y_{i} \right))^{2}  \right) \\
& = (1-\pi_{i})^{2}\pi_{i}+(0-\pi_{i})^{2}(1-\pi_{i}) \\
& = (1-\pi_{i})[(1-\pi_{i})\pi_{i}+\pi_{i}^{2}] \\
& = (1-\pi_{i})\pi_{i} \\
& = E(1-Y_{i})E(Y_{i})
\end{split}
\end{equation}

The variance of the response variable $Y_{i}$ (and thus of the error $\epsilon_{i}$) depends on the mean of $Y_{i}$, and consequently is not a constant.

\newthought{Conclusion}
The three problems cited above make it clear that in general, the basic conditions for a linear regression are \emph{not} met when the response variable is dichotomous.

\subsection{Introducing the ''sigmoid" or ''logistic" function}
Just as in the case of linear regression we can \emph{see} that there is some sort of connection between $y$ an $x$, which is very clear in the scatterplot on the left of Figure~\ref{fig:distinct}, almost non existent on the right of Figure~\ref{fig:distinct} and a little tentative in the middle. 

We could interpret these data by saying that $y_{i}$ is the result of a Bernouilli experiment: this experiment has two outcomes (''1" and ''0") with the following probabilities:
\begin{equation}
  \begin{split}
  P[y_{i}=1] & =p(x_{i}) \\
  P[y_{i}=0] &= 1-p(x_{i})
  \end{split}
\end{equation}

The probability $P[y_{i}=1]=p(x_{i})$ \emph{changes} with $x_{i}$: for small values of $x_{i}$ it will be ''0", for large values of $x_{i}$ it will be ''1", and there is a region $[a \leq x_{i} \leq b]$ where the probability changes from ''0" to ''1". We could define $p(x_{i})$ as a linear change in this region:
\begin{equation}
  \begin{split}
  x<a & \quad p(x)=0 \\
  a \leq x \leq b & \quad p(x)=\frac{(x-a)}{(b-a)} \\
  x>b & \quad p(x)=1
  \end{split}
\end{equation}

But this is a crude approximation. An \emph{S-shape} or \emph{sigmoid} seems more appropriate. This function is given by:
\begin{equation}
  \sigma(t)=\frac{e^{t}}{1+e^{t}}=\frac{1}{1+e^{-t}}
\end{equation}

This sigmoid function will be zero for $t \rightarrow -\infty$, will be one for $t \rightarrow +\infty$, and will be $0.5$ for $t=0$. We can make this sigmoid function dependent on the independent variable $x$ when $t=f(x)$. The simplest function is a linear one:
\begin{equation}
  t = \beta_{0} + \beta_{1}x
\end{equation}

The probability $P[y_{i}=1]=p(x_{i})$ is then:
\begin{equation}
  p(x_{i}) = \frac{1}{1+e^{-(\beta_{0} + \beta_{1}x_{i})}}
\end{equation}

From the definition of the logistic function it follows that
\begin{equation}
  \begin{split}
  odds &= \frac{p(x_{i})}{1-p(x_{i})} = e^{\beta_0 + \beta_{1}x_{i}} \\
  logit(p(x_{i})) &= ln(odds) = ln \left( \frac{p(x_{i})}{1-p(x_{i})}  \right)=\beta_{0} + \beta_{1}x_{i}
  \end{split}
\end{equation}

\subsection{What does the logistic function look like?}

We can see that
\begin{equation}
\begin{split}
\lim_{x\to -\infty} \frac{e^{\beta_{0}+\beta_{1}x}}{1+e^{\beta_{0}+\beta_{1}x}} &= 0 \\
\lim_{x\to \infty} \frac{e^{\beta_{0}+\beta_{1}x}}{1+e^{\beta_{0}+\beta_{1}x}} &= 1 \\
\frac{e^{\beta_{0}+\beta_{1}x}}{1+e^{\beta_{0}+\beta_{1}x}}(x=0) &= \frac{e^{\beta_{0}}}{1+e^{\beta_{0}}}
\end{split}
\end{equation}

The parameter $\beta_{0}$ is a \emph{place} factor (Figure~\ref{fig:place_and_form}-left): for positive values of $\beta_{0}$ it shifts the graph to the left, for negative values to the right. Parameter $\beta_{1}$ is a \emph{form} factor (Figure~\ref{fig:place_and_form}-right): for high values of $\beta_{1}$ it squeezes the graph to the center, for low values it streches the graph. Negative values of $\beta_{1}$ makes the sigmoid function go from high (1) for negative values of $x$ to low (0) for positive values of $x$.

<<label=place_and_form,fig=TRUE,include=FALSE, echo=FALSE>>=
df_pandf <- data.frame(x=seq(-10,10,0.5),y1=0, y2=0, y3=0, y4=0, y5=0, y6=0, y7=0, y8=0)
df_pandf$y1 <- 1/(1+exp(-5-df_pandf$x))
df_pandf$y2 <- 1/(1+exp(0-df_pandf$x))
df_pandf$y3 <- 1/(1+exp(+5-df_pandf$x))
p1 <- ggplot(data=df_pandf, aes(x=x)) + 
  geom_line(aes(y=y1), color="red") +
  geom_line(aes(y=y2), color="black") +
  geom_line(aes(y=y3), color="blue") +
  labs(title="beta0\nchanges place", xlab="x", ylab="y") +
  geom_text(x=-8, y=0.25, label="+5", color="red") +
  geom_text(x=-3, y=0.25, label="0", color="black") +
  geom_text(x=2.3, y=0.25, label="-5", color="blue") +
  JT.theme
df_pandf$y4 <- 1/(1+exp(0-2.5*df_pandf$x))
df_pandf$y5 <- 1/(1+exp(0-1*df_pandf$x))
df_pandf$y6 <- 1/(1+exp(0-0.25*df_pandf$x))
p2 <- ggplot(data=df_pandf, aes(x=x)) + 
  geom_line(aes(y=y4), color="red") +
  geom_line(aes(y=y5), color="black") +
  geom_line(aes(y=y6), color="blue") +
  geom_text(x=2, y=0.25, label="2.5", color="red") +
  geom_text(x=-2, y=0.25, label="1", color="black") +
  geom_text(x=-8, y=0.25, label="0.25", color="blue") +
  labs(title="beta1\nchanges form", xlab="x", ylab="y") +
  JT.theme
df_pandf$y7 <- 1/(1+exp(0-1*df_pandf$x))
df_pandf$y8 <- 1/(1+exp(0+1*df_pandf$x))
p3 <- ggplot(data=df_pandf, aes(x=x)) + 
  geom_line(aes(y=y7), color="red") +
  geom_line(aes(y=y8), color="blue") +
  geom_text(x=-4, y=0.25, label="+1", color="red") +
  geom_text(x=4, y=0.25, label="-1", color="blue") +
  labs(title="sign of beta1\nchanges direction", xlab="x", ylab="y") +
  JT.theme
grid.arrange(p1, p2, p3, ncol=3)
@

\begin{figure}
\includegraphics[width=1\textwidth, height=200pt]{LR-place_and_form}
\caption{Place and form}
\label{fig:place_and_form}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}


\subsection{Finding the coefficients $\beta_{0}$ and $\beta_{1}$}

In linear regression we determined the coefficients $\beta_{0}$ and $\beta_{1}$ using the \emph{Least Squares} criterium.

\chapter{Pearson: O-ring failure}

\section{Logistic regression}

<<label=scatter,fig=TRUE,include=FALSE, echo=FALSE>>=
O.ring <- data.frame(tempC=c(12, 13, 14, 17, 18, 19, 19, 19, 20, 20.5, 21, 21, 21, 21, 22, 23, 24, 24, 25, 25, 25.5, 26, 27, 27.2), failure=c(1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0))
O.ring$tempF <- O.ring$tempC*1.8 + 32
ggplot(data=O.ring) + 
  geom_point(aes(x=tempF, y=failure)) +
    labs(title="Scatterplot O-ring failure", xlab="temperature (F)", ylab="failure: 1=yes, 0=no") +
  JT.theme
@

\begin{marginfigure}
\includegraphics[width=1\textwidth]{LR-scatter}
\caption{Scatterplot of O-ring failure as a function of temperature}
\label{fig:scatter}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

<<label=scatterplusmodel,fig=TRUE,include=FALSE, echo=FALSE>>=
modF <- glm(failure~tempF,data=O.ring,family=binomial(link="logit"))
modelF <- data.frame(x=seq(52, 82, 1), y=0)
modelF$y <- 1/(1+exp(-(modF$coefficients[1] + modF$coefficients[2]*modelF$x)))
ggplot(data=O.ring, aes(x=tempF, y=failure)) + 
  geom_point() + 
  geom_line(data = modelF, aes(x=x, y=y), colour="red") +
  JT.theme            
@

<<>>=
summary(modF)
@
\begin{marginfigure}
\includegraphics[width=1\textwidth]{LR-scatterplusmodel}
\caption{Scatterplot and logistic regression model}
\label{fig:scatterplusmodel}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

\newpage
\textbf{Thanks} \\
\medskip
R Core Team (2018). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.
\medskip
<<>>=
sessionInfo()
@

\end{document}