\documentclass{tufte-book}
\usepackage{graphicx}  % werken met figuren
\usepackage{gensymb} % werken met wetenschappelijke eenheden\usepackage{geometry}
\usepackage{changepage} % http://ctan.org/pkg/changepage
\usepackage[dutch,british]{babel} % instelling van de taal (woordsplitsing, spellingscontrole)
\usepackage[parfill]{parskip} % Paragrafen gescheiden door witte lijn en geen inspringing
\usepackage[font=small,skip=3pt]{caption} % Minder ruimte tussen figuur/table en ondertitel. Ondertitel klein
\usepackage{capt-of}
\usepackage{indentfirst}
\setlength{\parindent}{0.7cm}
\usepackage{enumitem} % Laat enumerate werken met letters
\usepackage{url}
\usepackage{lipsum}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
% Prints a trailing space in a smart way.
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{amsmath}

\DeclareGraphicsExtensions{.pdf,.png,.jpg}

% Alter some LaTeX defaults for better treatment of figures:
% See p.105 of "TeX Unbound" for suggested values.
% See pp. 199-200 of Lamport's "LaTeX" book for details.
%   General parameters, for ALL pages:
    \renewcommand{\topfraction}{0.9}	% max fraction of floats at top
    \renewcommand{\bottomfraction}{0.9}	% max fraction of floats at bottom
%   Parameters for TEXT pages (not float pages):
    \setcounter{topnumber}{2}
    \setcounter{bottomnumber}{2}
    \setcounter{totalnumber}{4}     % 2 may work better
    \renewcommand{\textfraction}{0.1}	% allow minimal text w. figs
%   Parameters for FLOAT pages (not text pages):
    \renewcommand{\floatpagefraction}{0.8}	% require fuller float pages
% N.B.: floatpagefraction MUST be less than topfraction !!
\setcounter{secnumdepth}{3}

\newcommand{\tthdump}[1]{#1}

\newcommand{\openepigraph}[2]{
  \begin{fullwidth}
  \sffamily\large
    \begin{doublespace}
      \noindent\allcaps{#1}\\ % epigraph
      \noindent\allcaps{#2} % author
    \end{doublespace}
  \end{fullwidth}
}


\usepackage{makeidx}
\makeindex

\title{Logistic Regression}
\author{Jan Trommelmans}

\begin{document}
\SweaveOpts{concordance=TRUE,prefix.string=LR}
\setkeys{Gin}{width=1.1\marginparwidth} %% Sweave

<<echo=FALSE>>=
library(tidyverse)
library(scatterplot3d)
@

% Setting the ggplot theme:
<<echo=FALSE>>=
JT.theme <- theme(panel.border = element_rect(fill = NA, colour = "gray10"),
                  panel.background = element_blank(),
                  panel.grid.major = element_line(colour = "gray85"),
                  panel.grid.minor = element_line(colour = "gray85"),
                  panel.grid.major.x = element_line(colour = "gray85"),
                  axis.text = element_text(size = 8 , face = "bold"),
                  axis.title = element_text(size = 9 , face = "bold"),
                  plot.title = element_text(size = 12 , face = "bold"),
                  strip.text = element_text(size = 8 , face = "bold"),
                  strip.background = element_rect(colour = "black"),
                  legend.text = element_text(size = 8),
                  legend.title = element_text(size = 9 , face = "bold"),
                  legend.background = element_rect(fill = "white"),
                  legend.key = element_rect(fill = "white"))
@

% Functions

\frontmatter
\chapter*{Logistic Regression}

\mainmatter
\chapter{Why do we need a logistic regression?}

\section{Problems with a linear regression}

\subsection{Y is a discrete variable}
When the response variable $Y$ in \emph{qualitative} rather than \emph{quantitative}, linear regression is not the best method to link $Y$ with the controllable factors $x_{i}$\sidenote{Y (in capital) is a probability variable, x (lower case) is known}. Linear regression is well suited for \emph{continuous} variables. Logistic regression is better in the case of \emph{discrete} variables.

Let us start with the situation where the response variable $Y$ can only have two (discrete) levels ''0" and ''1", and that there is only one controllabel factor $x$. This points us into the direction of a \emph{dichotomous} event: the image of $Y$ is $\{0,1\}$, with $P[Y=1]=\pi$ and $P[Y=0]=1-\pi$. We do not know all values of $Y$, but we have a sample (size=$n$) of $n$ pairs $(x_{i}, Y_{i})$. However, the probability $\pi$ could be different for differend values of $x_{i}$:

\begin{equation}
P[Y_{i}=1]=\pi_{i} \quad and \quad P[Y_{i}=0]=1-\pi_{i}
\end{equation}

The expected value of $Y_{i}$ is

\begin{equation}
E(Y_{i})=1\pi_{i} + 0(1-\pi_{i})=\pi_{i}
\label{eq:meanpi}
\end{equation}

When we use a \emph{linear regression} we take it that the relation between $Y$ and $x$ can be written as:

\begin{equation}
Y=\beta_{0} + \beta_{1}x
\end{equation}

The pairs $(x_{i}, Y_{i})$ will not neccesarily lie on the theoretical regression line: there will be some error $\epsilon_{i}$

\begin{equation}
Y_{i}=\beta_{0} + \beta_{1}x_{i} + \epsilon_{i}
\end{equation}

\subsection{Problem 1: limits on the possible values of the linear regression model}

When we calculate the expected value of $Y_{i}$ we get:

\begin{equation}
E(Y_{i})=E\left( \beta_{0} + \beta_{1}x_{i} + \epsilon_{i}  \right) = \beta_{0} + \beta_{1}x_{i}
\label{eq:meanlin}
\end{equation}

From \ref{eq:meanpi} and \ref{eq:meanlin} it follows that

\begin{equation}
\pi_{i}=\beta_{0} + \beta_{1}x_{i}
\label{eq:linkpimean}
\end{equation}

This means that all the values of $\beta_{0} + \beta_{1}x_{i}$ \emph{must} lie between 0 and 1, because $\pi_{i}$ is a probability. 

\subsection{Problem 2: the error term $\epsilon_{i}$ is not normally distributed}

From \ref{eq:linkpimean} it follows that the error can only have two values:

\begin{equation}
\begin{split}
\epsilon_{i}&=1-\beta_{0} - \beta_{1}x_{i} \quad if \quad Y_{i}=1 \\
\epsilon_{i}&=-\beta_{0} - \beta_{1}x_{i} \quad if \quad Y_{i}=0
\end{split}
\end{equation}

With only two possible values, $\epsilon_{i}$ cannot be normally distributed.

\subsection{Problem 3: the variance of the error $\epsilon_{i}$ is not constant}

The variance of the error is equal to the variance of the response variable, because
\begin{equation}
var(\epsilon_{i})=var(Y_{i}-\pi_{i})=var(Y_{i}) \quad because \quad \pi_{i}=cnst
\end{equation}

The variance of the response variable is:
\begin{equation}
\begin{split}
var(Y_{i}) & \overset{\Delta}{=} E\left( (Y_{i} - E\left( Y_{i} \right))^{2}  \right) \\
& = (1-\pi_{i})^{2}\pi_{i}+(0-\pi_{i})^{2}(1-\pi_{i}) \\
& = (1-\pi_{i})[(1-\pi_{i})\pi_{i}+\pi_{i}^{2}] \\
& = (1-\pi_{i})\pi_{i} \\
& = E(1-Y_{i})E(Y_{i})
\end{split}
\end{equation}

The variance of the response variable $Y_{i}$ (and thus of the error $\epsilon_{i}$) depends on the mean of $Y_{i}$, and consequently is not a constant.

\subsection{Conclusion}
\newthought{The three problems} cited above make it clear that in general, the basic conditions for a linear regression are \emph{not met} when the response variable is dichotomous.

\section{Logistic regression}

\subsection{The logit function}

Instead of using a linear relation between the response variable $Y$ and the control variable x, we can use another function. This function should of course remove all, or most, of the problems cited above. The \emph{logit}-function is often used.

\begin{equation}
\begin{split}
E(Y_{i})&= \beta_{0} + \beta_{1}x_{i} \quad (linear) \\
E(Y_{i})&= \frac{e^{\beta_{0}+\beta_{1}x_{i}}}{1+e^{\beta_{0}+\beta_{1}x_{i}}} \quad (logit) 
\end{split}
\end{equation}

From this definition it follows that
\begin{equation}
e^{\beta_{0}+\beta_{1}x_{i}}=\frac{E(Y_{i})}{(1-E(Y_{i})}
\end{equation}

This is called the \emph{odds ratio}.

\subsection{Finding the coefficients $\beta_{0}$ and $\beta_{1}$}

In linear regression we determined the coefficients $\beta_{0}$ and $\beta_{1}$ using the \emph{Least Squares} criterium.

\chapter{Pearson: O-ring failure}

\section{Logistic regression}

<<label=scatter,fig=TRUE,include=FALSE, echo=FALSE>>=
O.ring <- data.frame(tempC=c(12, 13, 14, 17, 18, 19, 19, 19, 20, 20.5, 21, 21, 21, 21, 22, 23, 24, 24, 25, 25, 25.5, 26, 27, 27.2), failure=c(1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0))
O.ring$tempF <- O.ring$tempC*1.8 + 32
ggplot(data=O.ring) + 
  geom_point(aes(x=tempF, y=failure)) +
    labs(title="Scatterplot O-ring failure", xlab="temperature (F)", ylab="failure: 1=yes, 0=no") +
  JT.theme
@

\begin{marginfigure}
\includegraphics[width=1\textwidth]{LR-scatter}
\caption{Scatterplot of O-ring failure as a function of temperature}
\label{fig:scatter}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

<<label=scatterplusmodel,fig=TRUE,include=FALSE, echo=FALSE>>=
modF <- glm(failure~tempF,data=O.ring,family=binomial(link="logit"))
modelF <- data.frame(x=seq(52, 82, 1), y=0)
modelF$y <- 1/(1+exp(-(modF$coefficients[1] + modF$coefficients[2]*modelF$x)))
ggplot(data=O.ring, aes(x=tempF, y=failure)) + 
  geom_point() + 
  geom_line(data = modelF, aes(x=x, y=y), colour="red") +
  JT.theme            
@

<<>>=
summary(modF)
@
\begin{marginfigure}
\includegraphics[width=1\textwidth]{LR-scatterplusmodel}
\caption{Scatterplot and logistic regression model}
\label{fig:scatterplusmodel}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

\end{document}